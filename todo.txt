[cite_start]Here is a project plan for the term project [cite: 1] based on your assignment details and the N-Body Simulation problem.

## Term Project: N-Body Simulation with CUDA

[cite_start]This plan outlines the steps to implement a high-performance N-Body simulation, fulfilling the requirements of the term project[cite: 1].

---

### [cite_start]Step 1: Problem and Dataset Selection [cite: 5]

* **Problem:** The **N-Body Simulation**. This is a classic computation problem that models the interaction (e.g., gravitational force) of $N$ particles. The core task is to calculate the net force on each particle by summing the forces from all other $N-1$ particles. This $O(N^2)$ complexity is computationally intensive and ideal for CUDA acceleration.
* **Dataset:** A publicly available astrophysical dataset will be used. For example, initial conditions (positions, velocities, masses) for a **galaxy collision simulation** (like Milky Way vs. Andromeda) or a star cluster. [cite_start]These datasets provide the "large data" [cite: 12] necessary to demonstrate a significant performance difference.

[cite_start]*(This problem is not a standard lab assignment [cite: 6] [cite_start]and is a valid choice for the project[cite: 15].)*

### [cite_start]Step 2: Sequential Solution Design [cite: 7]

* **Implementation:** The best possible *direct* sequential solution is an all-pairs force calculation.
* **Algorithm:**
    1.  Implement a main loop that iterates over each time step.
    2.  Inside the time step, use a nested loop structure. The outer loop iterates from $i = 1$ to $N$ (for each particle).
    3.  The inner loop iterates from $j = 1$ to $N$.
    4.  Inside the inner loop, if $i \neq j$, calculate the force $\mathbf{F}_{ij}$ exerted by particle $j$ on particle $i$ using Newton's law of gravitation:
        $$\mathbf{F}_{ij} = G \frac{m_i m_j}{|\mathbf{r}_j - \mathbf{r}_i|^3} (\mathbf{r}_j - \mathbf{r}_i)$$
    5.  Accumulate this force into a `total_force` vector for particle $i$.
    6.  After the inner loop completes, use the `total_force` to find the acceleration ($a = F/m_i$).
    7.  Update the velocity and position of particle $i$ using a simple numerical integration method (like the Euler method).
* **Justification:** This $O(N^2)$ approach is the "best possible" sequential solution for a *direct* (non-approximate) simulation. It serves as the most accurate baseline for measuring the parallel solution's speedup, as it computes every interaction precisely.

### [cite_start]Step 3: Parallel Solution Design [cite: 8]

* **Design:** The parallel solution will map the force calculation for each particle to a separate GPU thread.
* **Kernel Logic:**
    1.  A single CUDA kernel will be launched with $N$ threads (e.g., in a 1D grid), where `threadIdx.x + blockIdx.x * blockDim.x` maps to a unique particle `idx`.
    2.  Each thread `idx` is responsible for calculating the total force on particle `idx`.
    3.  [cite_start]**Optimization (for Creativity/Efficiency [cite: 16]):** To avoid the $O(N^2)$ global memory reads, a **tiling** approach with shared memory will be used.
    4.  The kernel will loop through the $N$ particles in "tiles" (chunks) of size `blockDim.x`.
    5.  In each tile iteration:
        * All threads in a block load one particle's data (position, mass) from global memory into a `__shared__` memory array.
        * Threads are synchronized using `__syncthreads()`.
        * Each thread iterates through the particles *in the shared memory tile*, computing and accumulating the forces.
        * Another `__syncthreads()` ensures all threads are done before loading the next tile.
    6.  After all tiles are processed, the thread writes its final calculated acceleration to global memory.
    7.  Vector data types (e.g., `float4`) will be used for position and velocity to ensure **coalesced memory access**, maximizing memory bandwidth.
* [cite_start]**Justification:** This solution is "good" [cite: 8] because it parallelizes the most expensive part of the problem. By using shared memory tiling, it drastically reduces global memory latency, which is the main bottleneck, and efficiently utilizes the GPU's thousands of cores. [cite_start]This design is expected to achieve a massive speedup over the $O(N^2)$ CPU version, fulfilling the requirement to outperform the sequential counterpart[cite: 12].

### [cite_start]Step 4: Sequential Implementation (CPU) [cite: 9]

* A C++ program will be created to implement the sequential solution as described in Step 2.
* It will include functions to read the initial dataset, run the simulation for a specified number of steps, and time the execution.

### [cite_start]Step 5: Parallel Implementation (CPU-GPU) [cite: 10]

* A CUDA (C++/`.cu`) program will be created.
* **Host Code (CPU):**
    * Manages allocating memory on both the host (`malloc`) and device (`cudaMalloc`).
    * Copies initial particle data from host to device (`cudaMemcpy`).
    * Calls the CUDA kernel (from Step 3) inside the main simulation loop.
    * Copies final results back from device to host.
* **Device Code (GPU):**
    * Contains the `__global__` kernel for force calculation and helper `__device__` functions.
* The program will include robust timing (e.g., using CUDA events) to measure only the kernel and data transfer time, allowing for a fair comparison against the CPU version.

---

### Submission and Presentation Checklist

* [cite_start]**Submission (Due: Wed 5 Nov)[cite: 19, 23]:**
    * A GitHub repository link will be submitted.
    * The repository will contain:
        * [cite_start]A folder (`src/`) with all source files (sequential `.cpp`, parallel `.cu`, `Makefile`)[cite: 21].
        * A folder (`data/`) with a sample dataset or a script to download it.
        * [cite_start]A `README.md` file (the "document file") detailing the project, the algorithms used, and clear instructions on how to compile and run both the sequential and parallel versions[cite: 22].
        * [cite_start]The final presentation file (`presentation.pdf`)[cite: 22].
* [cite_start]**Presentation (Date: Thu 6 Nov)[cite: 26]:**
    * [cite_start]A ~15-minute presentation [cite: 24] will be prepared, covering:
        * [cite_start]Problem definition (N-Body) and dataset[cite: 15].
        * The sequential $O(N^2)$ algorithm.
        * [cite_start]The parallel CUDA design, focusing on the shared memory tiling technique[cite: 16].
        * [cite_start]A "Results" section with graphs showing the performance (runtime in ms vs. $N$) of the CPU vs. GPU solutions, demonstrating the speedup[cite: 12].
        * [cite_start]Discussion of correctness and challenges[cite: 17].